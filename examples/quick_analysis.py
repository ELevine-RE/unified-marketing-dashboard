#!/usr/bin/env python3
"""
Quick Analysis Script
====================

Provides a quick daily analysis of the L.R - PMax - General campaign including
metrics, asset groups, search themes, and phase status.

This script is designed for daily check-ins and monitoring.
"""

import os
import sys
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Any
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ads.guardrails import PerformanceMaxGuardrails
from ads.phase_manager import CampaignPhaseManager
from ads.ensure_baseline_config import BaselineConfigValidator
from ads.notifications import NotificationManager
from google_ads_manager import GoogleAdsManager

console = Console()

class QuickAnalysis:
    """
    Provides quick analysis of campaign performance and status.
    
    This class aggregates data from multiple sources to provide a comprehensive
    daily overview of campaign health and progress.
    """
    
    def __init__(self):
        """Initialize the quick analysis system."""
        self.manager = GoogleAdsManager()
        self.guardrails = PerformanceMaxGuardrails()
        self.phase_manager = CampaignPhaseManager()
        self.baseline_validator = BaselineConfigValidator()
        self.notification_manager = NotificationManager()
        
        # Campaign configuration
        self.CAMPAIGN_NAME = "L.R - PMax - General"
        self.CUSTOMER_ID = "5426234549"  # Campaign is in manager account
        self.MANAGER_ID = "5426234549"
    
    def run_quick_analysis(self) -> Dict:
        """
        Run comprehensive quick analysis of the campaign.
        
        Returns:
            Dictionary containing all analysis results
        """
        try:
            console.print(Panel("üìä Quick Analysis: L.R - PMax - General", style="bold blue"))
            
            # Get campaign data
            campaign_data = self._get_campaign_data()
            if not campaign_data:
                console.print("[red]‚ùå Campaign not found or API error[/red]")
                return {"error": "Campaign not found"}
            
            # Store campaign data for leads generation
            self.campaign_data = campaign_data
            
            # Get leads data from CRM (Sierra Interactive)
            leads_data = self._get_leads_data_from_crm()
            
            # Run analysis components
            results = {
                "campaign_info": campaign_data,
                "daily_metrics": self._analyze_daily_metrics(campaign_data),
                "lqs_analysis": self.manager.analyze_lead_quality_performance(leads_data, period_days=30),
                "asset_groups": self._analyze_asset_groups(campaign_data),
                "search_themes": self._analyze_search_themes(campaign_data),
                "phase_status": self._analyze_phase_status(campaign_data),
                "guardrail_status": self._analyze_guardrail_status(campaign_data),
                "baseline_status": self._analyze_baseline_status()
            }
            
            # Display results
            self._display_analysis(results)
            
            # Send daily recap notification
            self._send_daily_recap_notification(results)
            
            return results
            
        except Exception as e:
            console.print(f"[red]‚ùå Error running quick analysis: {str(e)}[/red]")
            return {"error": str(e)}
    
    def _get_campaign_data(self) -> Optional[Dict]:
        """Get comprehensive campaign data from Google Ads API."""
        try:
            # Query for campaign performance data
            query = f"""
            SELECT
                campaign.id,
                campaign.name,
                campaign.status,
                campaign_budget.amount_micros,
                campaign_budget.delivery_method,
                metrics.impressions,
                metrics.clicks,
                metrics.conversions,
                metrics.cost_micros,
                metrics.conversions_value,
                segments.date
            FROM campaign
            WHERE campaign.name = '{self.CAMPAIGN_NAME}'
            AND campaign.advertising_channel_type = 'PERFORMANCE_MAX'
            AND segments.date DURING LAST_30_DAYS
            ORDER BY segments.date DESC
            """
            
            response = self.manager.google_ads_service.search(
                customer_id=self.CUSTOMER_ID,
                query=query
            )
            
            # Aggregate data
            campaign_data = {
                "campaign_id": None,
                "campaign_name": self.CAMPAIGN_NAME,
                "status": None,
                "daily_budget": 0,
                "target_cpa": None,
                "bidding_strategy": None,
                "metrics": {
                    "7d": {"impressions": 0, "clicks": 0, "conversions": 0, "cost": 0, "value": 0},
                    "30d": {"impressions": 0, "clicks": 0, "conversions": 0, "cost": 0, "value": 0}
                },
                            "cpl_7d": 0,
                "cpl_30d": 0
            }
            
            for row in response:
                if not campaign_data["campaign_id"]:
                    campaign_data["campaign_id"] = row.campaign.id
                    campaign_data["status"] = row.campaign.status.name
                    campaign_data["daily_budget"] = row.campaign_budget.amount_micros / 1000000
                    campaign_data["target_cpa"] = None  # Not available in this query
                    campaign_data["bidding_strategy"] = "TARGET_CPA"  # Default for Performance Max
                
                # Aggregate metrics by date range
                row_date = datetime.strptime(row.segments.date, '%Y-%m-%d').date()
                days_ago = (date.today() - row_date).days
                
                if days_ago <= 7:
                    campaign_data["metrics"]["7d"]["impressions"] += row.metrics.impressions
                    campaign_data["metrics"]["7d"]["clicks"] += row.metrics.clicks
                    campaign_data["metrics"]["7d"]["conversions"] += row.metrics.conversions
                    campaign_data["metrics"]["7d"]["cost"] += row.metrics.cost_micros / 1000000
                    campaign_data["metrics"]["7d"]["value"] += row.metrics.conversions_value / 1000000
                
                if days_ago <= 30:
                    campaign_data["metrics"]["30d"]["impressions"] += row.metrics.impressions
                    campaign_data["metrics"]["30d"]["clicks"] += row.metrics.clicks
                    campaign_data["metrics"]["30d"]["conversions"] += row.metrics.conversions
                    campaign_data["metrics"]["30d"]["cost"] += row.metrics.cost_micros / 1000000
                    campaign_data["metrics"]["30d"]["value"] += row.metrics.conversions_value / 1000000
            
            # Calculate derived metrics
            if campaign_data["metrics"]["7d"]["conversions"] > 0:
                campaign_data["cpl_7d"] = campaign_data["metrics"]["7d"]["cost"] / campaign_data["metrics"]["7d"]["conversions"]
            
            if campaign_data["metrics"]["30d"]["conversions"] > 0:
                campaign_data["cpl_30d"] = campaign_data["metrics"]["30d"]["cost"] / campaign_data["metrics"]["30d"]["conversions"]
            
            # LQS metrics will be calculated by the LQS engine using real data
            
            return campaign_data
            
        except Exception as e:
            console.print(f"[red]Error getting campaign data: {str(e)}[/red]")
            return None
    
    def _get_leads_data_from_crm(self) -> List[Dict]:
        """
        Get leads data from CRM (placeholder for Sierra Interactive integration).
        
        Returns:
            List of lead dictionaries with 'lqs' key
        """
        # TODO: Replace with actual Sierra Interactive API call
        # For now, return sample data based on campaign conversions
        
        sample_leads = []
        total_conversions = self.campaign_data.get("metrics", {}).get("30d", {}).get("conversions", 0) if hasattr(self, 'campaign_data') else 0
        
        if total_conversions > 0:
            # Generate sample leads based on conversion count
            for i in range(total_conversions):
                # Simulate realistic LQS distribution
                import random
                lqs_scores = [3, 4, 5, 6, 7, 8, 9]  # Realistic LQS range
                weights = [0.1, 0.15, 0.2, 0.25, 0.15, 0.1, 0.05]  # Weighted distribution
                
                sample_leads.append({
                    "id": f"lead_{i+1:03d}",
                    "lqs": random.choices(lqs_scores, weights=weights)[0],
                    "source": "google_ads",
                    "campaign": self.CAMPAIGN_NAME,
                    "date": (datetime.now() - timedelta(days=random.randint(1, 30))).strftime("%Y-%m-%d")
                })
        else:
            # If no conversions, return a few sample leads for testing
            sample_leads = [
                {"id": "lead_001", "lqs": 7, "source": "google_ads", "campaign": self.CAMPAIGN_NAME, "date": "2024-01-15"},
                {"id": "lead_002", "lqs": 5, "source": "google_ads", "campaign": self.CAMPAIGN_NAME, "date": "2024-01-14"},
                {"id": "lead_003", "lqs": 8, "source": "google_ads", "campaign": self.CAMPAIGN_NAME, "date": "2024-01-13"},
            ]
        
        return sample_leads
    
    def _analyze_daily_metrics(self, campaign_data: Dict) -> Dict:
        """Analyze daily performance metrics."""
        metrics_7d = campaign_data["metrics"]["7d"]
        metrics_30d = campaign_data["metrics"]["30d"]
        
        return {
            "spend_7d": metrics_7d["cost"],
            "spend_30d": metrics_30d["cost"],
            "conversions_7d": metrics_7d["conversions"],
            "conversions_30d": metrics_30d["conversions"],
            "cpl_7d": campaign_data["cpl_7d"],
            "cpl_30d": campaign_data["cpl_30d"]
        }
    
    def _analyze_asset_groups(self, campaign_data: Dict) -> List[Dict]:
        """Analyze asset groups and their status."""
        try:
            # Query for asset groups
            query = f"""
            SELECT
                asset_group.id,
                asset_group.name,
                asset_group.status,
                asset_group.type,
                asset_group_asset.asset_group,
                asset_group_asset.asset,
                asset.type,
                asset.text_asset.text,
                asset.image_asset.file_size,
                asset.video_asset.file_size
            FROM asset_group
            WHERE asset_group.campaign = 'customers/{self.CUSTOMER_ID}/campaigns/{campaign_data["campaign_id"]}'
            """
            
            response = self.manager.google_ads_service.search(
                customer_id=self.CUSTOMER_ID,
                query=query
            )
            
            # Process asset groups
            asset_groups = {}
            
            for row in response:
                group_id = row.asset_group.id
                if group_id not in asset_groups:
                    asset_groups[group_id] = {
                        "id": group_id,
                        "name": row.asset_group.name,
                        "status": row.asset_group.status.name,
                        "type": row.asset_group.type.name,
                        "assets": {
                            "headlines": 0,
                            "long_headlines": 0,
                            "descriptions": 0,
                            "business_name": 0,
                            "logos_1_1": 0,
                            "logos_4_1": 0,
                            "images_1_91_1": 0,
                            "images_1_1": 0,
                            "videos": 0
                        }
                    }
                
                # Count assets by type
                asset_type = row.asset.type.name
                if asset_type == "TEXT":
                    if hasattr(row.asset, 'text_asset'):
                        text = row.asset.text_asset.text
                        if len(text) <= 30:
                            asset_groups[group_id]["assets"]["headlines"] += 1
                        elif len(text) <= 90:
                            asset_groups[group_id]["assets"]["long_headlines"] += 1
                        else:
                            asset_groups[group_id]["assets"]["descriptions"] += 1
                elif asset_type == "IMAGE":
                    asset_groups[group_id]["assets"]["images_1_1"] += 1
                elif asset_type == "VIDEO":
                    asset_groups[group_id]["assets"]["videos"] += 1
            
            return list(asset_groups.values())
            
        except Exception as e:
            console.print(f"[red]Error analyzing asset groups: {str(e)}[/red]")
            return []
    
    def _analyze_search_themes(self, campaign_data: Dict) -> List[Dict]:
        """Analyze top search themes and performance."""
        try:
            # Query for search themes
            query = f"""
            SELECT
                search_term_view.search_term,
                metrics.impressions,
                metrics.clicks,
                metrics.conversions,
                metrics.cost_micros
            FROM search_term_view
            WHERE segments.date >= '2024-01-01'
            ORDER BY metrics.impressions DESC
            LIMIT 10
            """
            
            response = self.manager.google_ads_service.search(
                customer_id=self.CUSTOMER_ID,
                query=query
            )
            
            search_themes = []
            for row in response:
                search_themes.append({
                    "search_term": row.search_term_view.search_term,
                    "impressions": row.metrics.impressions,
                    "clicks": row.metrics.clicks,
                    "conversions": row.metrics.conversions,
                    "cost": row.metrics.cost_micros / 1000000
                })
            
            return search_themes
            
        except Exception as e:
            console.print(f"[red]Error analyzing search themes: {str(e)}[/red]")
            return []
    
    def _analyze_phase_status(self, campaign_data: Dict) -> Dict:
        """Analyze current phase status and eligibility."""
        try:
            # Prepare metrics for phase analysis
            metrics = {
                "total_conversions": campaign_data["metrics"]["30d"]["conversions"],
                "campaign_age_days": 30,  # Simplified - would need actual campaign start date
                "cpl_7d": campaign_data["cpl_7d"],
                "cpl_30d": campaign_data["cpl_30d"],
                "days_since_last_change": 7,  # Simplified
                "current_cpl": campaign_data["cpl_30d"],
                "lead_quality_percent": 5.0,  # Simplified
                "current_pacing": 0.85,  # Simplified
                "days_under_tcpa": 0 if campaign_data["target_cpa"] is None else 30  # Simplified
            }
            
            # Determine current phase (simplified logic)
            current_phase = "phase_1"  # Default assumption
            if campaign_data["target_cpa"] is not None:
                current_phase = "phase_2"
            
            # Check phase eligibility
            eligibility = self.phase_manager.check_phase_eligibility(metrics, current_phase)
            
            # Check phase progress
            start_date = date.today() - timedelta(days=30)  # Simplified
            progress = self.phase_manager.check_phase_progress(
                start_date, date.today(), current_phase, eligibility.to_dict()
            )
            
            return {
                "current_phase": current_phase,
                "eligible_for_next": eligibility.eligible_for_next,
                "recommended_action": eligibility.recommended_action,
                "lagging": progress.lagging,
                "lag_alert": progress.lag_alert,
                "message": progress.message
            }
            
        except Exception as e:
            console.print(f"[red]Error analyzing phase status: {str(e)}[/red]")
            return {"error": str(e)}
    
    def _analyze_guardrail_status(self, campaign_data: Dict) -> Dict:
        """Analyze guardrail compliance status."""
        try:
            # Check for safety stop-loss conditions
            recent_spend = campaign_data["metrics"]["7d"]["cost"]
            daily_budget = campaign_data["daily_budget"]
            recent_conversions = campaign_data["metrics"]["7d"]["conversions"]
            
            safety_alerts = []
            
            # Check overspend with no conversions
            if recent_spend > daily_budget * 2 and recent_conversions == 0:
                safety_alerts.append(f"STOP-LOSS: Spend ${recent_spend:.2f} exceeds 2x budget with 0 conversions")
            
            # Check conversion drought
            if recent_conversions == 0:
                safety_alerts.append("STOP-LOSS: No conversions in last 7 days")
            
            return {
                "safety_alerts": safety_alerts,
                "daily_budget": daily_budget,
                "recent_spend": recent_spend,
                "recent_conversions": recent_conversions
            }
            
        except Exception as e:
            console.print(f"[red]Error analyzing guardrail status: {str(e)}[/red]")
            return {"error": str(e)}
    
    def _analyze_baseline_status(self) -> Dict:
        """Analyze baseline configuration status."""
        try:
            baseline_result = self.baseline_validator.ensure_baseline_config(
                self.CUSTOMER_ID, self.CAMPAIGN_NAME
            )
            
            return {
                "success": baseline_result.success,
                "issues_found": baseline_result.issues_found,
                "fixes_applied": baseline_result.fixes_applied,
                "errors": baseline_result.errors
            }
            
        except Exception as e:
            console.print(f"[red]Error analyzing baseline status: {str(e)}[/red]")
            return {"error": str(e)}
    
    def _display_analysis(self, results: Dict):
        """Display the analysis results in a formatted way."""
        # Daily Metrics
        metrics = results["daily_metrics"]
        console.print("\n[bold cyan]üìä Daily Metrics[/bold cyan]")
        
        metrics_table = Table(title="Performance Summary")
        metrics_table.add_column("Metric", style="bold")
        metrics_table.add_column("7 Days", justify="right")
        metrics_table.add_column("30 Days", justify="right")
        
        metrics_table.add_row("Spend", f"${metrics['spend_7d']:.2f}", f"${metrics['spend_30d']:.2f}")
        metrics_table.add_row("Conversions", str(metrics['conversions_7d']), str(metrics['conversions_30d']))
        metrics_table.add_row("CPL", f"${metrics['cpl_7d']:.2f}", f"${metrics['cpl_30d']:.2f}")
        
        console.print(metrics_table)
        
        # LQS Analysis
        if "lqs_analysis" in results and results["lqs_analysis"]:
            lqs_metrics = results["lqs_analysis"]["lqs_metrics"]
            console.print("\n[bold cyan]üéØ Lead Quality Score Analysis[/bold cyan]")
            
            lqs_table = Table(title="LQS Performance Summary")
            lqs_table.add_column("Metric", style="bold")
            lqs_table.add_column("Value", justify="right")
            lqs_table.add_column("Status", justify="center")
            
            lqs_table.add_row("Total Leads", str(lqs_metrics["total_leads"]), "‚úÖ" if lqs_metrics["total_leads"] > 0 else "‚ö†Ô∏è")
            lqs_table.add_row("High Quality Leads", str(lqs_metrics["high_quality_leads"]), "‚úÖ" if lqs_metrics["high_quality_leads"] > 0 else "‚ö†Ô∏è")
            lqs_table.add_row("Average LQS", f"{lqs_metrics['average_lqs']:.1f}", "‚úÖ" if lqs_metrics['average_lqs'] >= 6.0 else "‚ö†Ô∏è")
            lqs_table.add_row("High Quality Ratio", f"{lqs_metrics['high_quality_ratio']:.1%}", "‚úÖ" if lqs_metrics['high_quality_ratio'] >= 0.4 else "‚ö†Ô∏è")
            lqs_table.add_row("Cost per High-Quality Lead", f"${lqs_metrics['cphql']:.2f}", "‚úÖ" if lqs_metrics['cphql'] <= 300 else "‚ö†Ô∏è")
            
            console.print(lqs_table)
            
            # Display LQS recommendation if available
            if "recommendation" in results["lqs_analysis"] and results["lqs_analysis"]["recommendation"]["action"] != "maintain":
                rec = results["lqs_analysis"]["recommendation"]
                console.print(f"\n[bold yellow]üí° LQS Recommendation: {rec['action'].replace('_', ' ').title()} ({rec['confidence']:.0%} confidence)[/bold yellow]")
                for reason in rec["reasoning"][:2]:  # Show first 2 reasons
                    console.print(f"   ‚Ä¢ {reason}")
        
        # Asset Groups
        asset_groups = results["asset_groups"]
        if asset_groups:
            console.print("\n[bold cyan]üé® Asset Groups[/bold cyan]")
            
            asset_table = Table(title="Asset Group Status")
            asset_table.add_column("Group", style="bold")
            asset_table.add_column("Status", justify="center")
            asset_table.add_column("Headlines", justify="center")
            asset_table.add_column("Long Headlines", justify="center")
            asset_table.add_column("Descriptions", justify="center")
            asset_table.add_column("Images", justify="center")
            asset_table.add_column("Videos", justify="center")
            
            for group in asset_groups:
                assets = group["assets"]
                status_color = "green" if group["status"] == "ENABLED" else "red"
                
                asset_table.add_row(
                    group["name"],
                    f"[{status_color}]{group['status']}[/{status_color}]",
                    str(assets["headlines"]),
                    str(assets["long_headlines"]),
                    str(assets["descriptions"]),
                    str(assets["images_1_1"] + assets["images_1_91_1"]),
                    str(assets["videos"])
                )
            
            console.print(asset_table)
        
        # Search Themes
        search_themes = results["search_themes"]
        if search_themes:
            console.print("\n[bold cyan]üîç Top Search Themes[/bold cyan]")
            
            search_table = Table(title="Top Performing Search Terms")
            search_table.add_column("Search Term", style="bold")
            search_table.add_column("Impressions", justify="right")
            search_table.add_column("Clicks", justify="right")
            search_table.add_column("Conversions", justify="right")
            search_table.add_column("Cost", justify="right")
            
            for theme in search_themes[:5]:  # Top 5
                search_table.add_row(
                    theme["search_term"],
                    f"{theme['impressions']:,}",
                    f"{theme['clicks']:,}",
                    str(theme["conversions"]),
                    f"${theme['cost']:.2f}"
                )
            
            console.print(search_table)
        
        # Phase Status
        phase_status = results["phase_status"]
        if "error" not in phase_status:
            console.print("\n[bold cyan]üéØ Phase Status[/bold cyan]")
            
            # Determine status line
            if phase_status["lag_alert"]:
                status_line = f"üö® Critical lag - {phase_status['message']}"
            elif phase_status["lagging"]:
                status_line = f"‚ö†Ô∏è Lagging - {phase_status['message']}"
            elif phase_status["eligible_for_next"]:
                status_line = f"‚úÖ Eligible for next phase - {phase_status['recommended_action']}"
            else:
                status_line = f"üìà On track - {phase_status['message']}"
            
            console.print(f"Current Phase: [bold]{phase_status['current_phase'].upper()}[/bold]")
            console.print(f"Status: {status_line}")
        
        # Guardrail Status
        guardrail_status = results["guardrail_status"]
        if "error" not in guardrail_status and guardrail_status["safety_alerts"]:
            console.print("\n[bold red]üö® Safety Alerts[/bold red]")
            for alert in guardrail_status["safety_alerts"]:
                console.print(f"‚Ä¢ {alert}")
        
        # Baseline Status
        baseline_status = results["baseline_status"]
        if "error" not in baseline_status:
            if baseline_status["success"]:
                console.print("\n[bold green]‚úÖ Baseline Configuration: All requirements met[/bold green]")
            else:
                console.print("\n[bold yellow]‚ö†Ô∏è Baseline Configuration Issues[/bold yellow]")
                for issue in baseline_status["issues_found"]:
                    console.print(f"‚Ä¢ {issue}")
    
    def _send_daily_recap_notification(self, results: Dict):
        """Send daily recap notification with phase status and alerts."""
        try:
            # Extract phase status
            phase_status = results.get("phase_status", {})
            
            # Extract lag alerts
            lag_alerts = []
            if phase_status.get("lagging"):
                lag_alerts.append(phase_status.get("message", "Phase lagging"))
            
            # Extract stop-loss alerts
            stop_loss_alerts = []
            guardrail_status = results.get("guardrail_status", {})
            if guardrail_status.get("safety_alerts"):
                stop_loss_alerts.extend(guardrail_status["safety_alerts"])
            
            # Extract planned changes (simplified - would need to track actual pending changes)
            planned_changes = []
            
            # Send notification
            self.notification_manager.send_daily_recap(
                phase_status=phase_status,
                lag_alerts=lag_alerts,
                planned_changes=planned_changes,
                stop_loss_alerts=stop_loss_alerts
            )
            
        except Exception as e:
            console.print(f"[red]Warning: Could not send daily recap notification: {str(e)}[/red]")

def main():
    """Run quick analysis."""
    analyzer = QuickAnalysis()
    results = analyzer.run_quick_analysis()
    
    if "error" in results:
        console.print(f"[red]Analysis failed: {results['error']}[/red]")
        return 1
    
    console.print("\n[bold green]‚úÖ Quick analysis completed successfully[/bold green]")
    return 0

if __name__ == "__main__":
    exit(main())
